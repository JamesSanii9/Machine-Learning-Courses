{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "351 Assignment 2\n",
    "James Sanii\n",
    "student id: 20111876\n",
    "net id: 17jcs9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first block of code imports the data from the train and test csv files and then loops to create the training image data from the photots provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from  matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import random\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "\n",
    "train_dir = 'train (2).csv'\n",
    "test_dir = 'test (2).csv'\n",
    "\n",
    "train = pd.read_csv(train_dir,sep='\\t')\n",
    "test = pd.read_csv(test_dir,sep='\\t')\n",
    "#print(train)\n",
    "temp_train_imgs = train['imageid']\n",
    "temp_test_imgs = test['imageid']\n",
    "\n",
    "mystring = '.jpg'\n",
    "train_imgs = [str(s) + mystring for s in temp_train_imgs]\n",
    "test_imgs = [str(s) + mystring for s in temp_test_imgs]\n",
    "\n",
    "X = [] #images\n",
    "\n",
    "for image in train_imgs:\n",
    "    #read in each image as greyscale\n",
    "    X.append(cv2.resize(cv2.imread('images/' +image), (60, 80), interpolation = cv2.INTER_CUBIC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates the one hot encoding used for the output variable for the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Bags  Bottomwear  Eyewear  Fragrance  Innerwear  Jewellery  Makeup  \\\n",
      "0         1           0        0          0          0          0       0   \n",
      "1         0           0        0          0          0          0       0   \n",
      "2         0           0        0          0          0          0       0   \n",
      "3         0           0        0          0          0          0       0   \n",
      "4         0           1        0          0          0          0       0   \n",
      "...     ...         ...      ...        ...        ...        ...     ...   \n",
      "40436     0           0        0          0          0          0       0   \n",
      "40437     0           0        0          0          0          0       0   \n",
      "40438     0           1        0          0          0          0       0   \n",
      "40439     0           0        0          0          0          0       0   \n",
      "40440     0           0        0          0          0          0       0   \n",
      "\n",
      "       Others  Sandal  Shoes  Topwear  Wallets  Watches  \n",
      "0           0       0      0        0        0        0  \n",
      "1           1       0      0        0        0        0  \n",
      "2           0       0      1        0        0        0  \n",
      "3           0       0      0        1        0        0  \n",
      "4           0       0      0        0        0        0  \n",
      "...       ...     ...    ...      ...      ...      ...  \n",
      "40436       0       0      0        1        0        0  \n",
      "40437       1       0      0        0        0        0  \n",
      "40438       0       0      0        0        0        0  \n",
      "40439       0       0      0        1        0        0  \n",
      "40440       1       0      0        0        0        0  \n",
      "\n",
      "[40441 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(train.label)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the X and Y variables to numpy arrays then normalize X\n",
    "Print out the shapes of the two variable to confirm they are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40441, 80, 60, 3)\n",
      "(40441, 13)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "#normalize X values between 0 and 1\n",
    "X = np.true_divide(X, 255)\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same idea as above but for the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 80, 60, 3)\n",
      "(4000, 13)\n"
     ]
    }
   ],
   "source": [
    "#replicate above for testing data\n",
    "X_test = []\n",
    "for image in test_imgs:\n",
    "    #read in each image as color\n",
    "    X_test.append(cv2.resize(cv2.imread('images/' +image), (60, 80), interpolation = cv2.INTER_CUBIC))\n",
    "    \n",
    "Y_test = pd.get_dummies(test.label)\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)\n",
    "X_test = np.true_divide(X_test, 255)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required libraries\n",
    "Then I created a simple outline of a CNN as seen in the class lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "import keras\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), activation = 'relu', input_shape =(80,60,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(13, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compile and fit the created model and see the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "632/632 [==============================] - 66s 104ms/step - loss: 0.8603 - accuracy: 0.7322\n",
      "Epoch 2/20\n",
      "632/632 [==============================] - 66s 105ms/step - loss: 0.2472 - accuracy: 0.9247\n",
      "Epoch 3/20\n",
      "632/632 [==============================] - 66s 104ms/step - loss: 0.1748 - accuracy: 0.9439\n",
      "Epoch 4/20\n",
      "632/632 [==============================] - 66s 105ms/step - loss: 0.1343 - accuracy: 0.9590\n",
      "Epoch 5/20\n",
      "632/632 [==============================] - 66s 104ms/step - loss: 0.1057 - accuracy: 0.9659\n",
      "Epoch 6/20\n",
      "632/632 [==============================] - 66s 104ms/step - loss: 0.0882 - accuracy: 0.9722\n",
      "Epoch 7/20\n",
      "632/632 [==============================] - 66s 104ms/step - loss: 0.0762 - accuracy: 0.9762\n",
      "Epoch 8/20\n",
      "632/632 [==============================] - 66s 105ms/step - loss: 0.0650 - accuracy: 0.9786\n",
      "Epoch 9/20\n",
      "632/632 [==============================] - 66s 104ms/step - loss: 0.0564 - accuracy: 0.9813\n",
      "Epoch 10/20\n",
      "632/632 [==============================] - 67s 105ms/step - loss: 0.0521 - accuracy: 0.9840\n",
      "Epoch 11/20\n",
      "632/632 [==============================] - 66s 105ms/step - loss: 0.0457 - accuracy: 0.9862\n",
      "Epoch 12/20\n",
      "632/632 [==============================] - 66s 105ms/step - loss: 0.0393 - accuracy: 0.9876\n",
      "Epoch 13/20\n",
      "632/632 [==============================] - 66s 105ms/step - loss: 0.0396 - accuracy: 0.9876\n",
      "Epoch 14/20\n",
      "632/632 [==============================] - 66s 105ms/step - loss: 0.0370 - accuracy: 0.9900\n",
      "Epoch 15/20\n",
      "632/632 [==============================] - 66s 105ms/step - loss: 0.0319 - accuracy: 0.9907\n",
      "Epoch 16/20\n",
      "632/632 [==============================] - 66s 105ms/step - loss: 0.0353 - accuracy: 0.9891\n",
      "Epoch 17/20\n",
      "632/632 [==============================] - 66s 105ms/step - loss: 0.0295 - accuracy: 0.9914\n",
      "Epoch 18/20\n",
      "632/632 [==============================] - 66s 104ms/step - loss: 0.0344 - accuracy: 0.9905\n",
      "Epoch 19/20\n",
      "632/632 [==============================] - 66s 104ms/step - loss: 0.0313 - accuracy: 0.9914\n",
      "Epoch 20/20\n",
      "632/632 [==============================] - 66s 104ms/step - loss: 0.0336 - accuracy: 0.9905\n",
      "Evaluate on test data\n",
      "32/32 [==============================] - 2s 42ms/step - loss: 0.4450 - accuracy: 0.9367\n",
      "test loss, test acc: [0.4450218975543976, 0.9367499947547913]\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "history = model.fit(X, Y, epochs=20, batch_size = 64, verbose = 1)\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_test, Y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has an accuracy of 0.9837 on the training data but an accurracy of 0.9477 on the testing data.\n",
    "Save the model so I can load it back in if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "#save the model\n",
    "model.save(\"my_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model summary gives the format of the model as well as the other weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 78, 58, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 39, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 37, 27, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1311232   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 13)                6669      \n",
      "=================================================================\n",
      "Total params: 1,374,221\n",
      "Trainable params: 1,374,221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the optimizer that is going to be used for the optimal model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#switch back to 0.0001 if worse results\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0005,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created second model.\n",
    "\n",
    "The changes in the model are as followed.\n",
    "\n",
    "Changed the optimizer. Looking online the optimizer that tended to have the best performance were variations of the Adam optimizer. When choosing the values for the Adam optimizer I kept the two beta values constant and tested results with diffrent learning rates. I started with the default which was 0.001 and this resulted in a model with similar results to Part 1. I then tried using a learning rate 10 times smaller of 0.0001 which was too slow, increased it to 0.0003 which was still too slow and struggled to get beyond 96% on testing data. I then tried it with a learning rate of 0.0005 which gave me similar results on the training data as model 1 but had increased results on the testing data to just above 96%. No learning rate schedule function was used since Adam has built in decay so manually decreasing the learning rate over time would be unnessessary. \n",
    "\n",
    "I added dropout layers after each Max pooling layer to reduce overfitting. I tested values of 0.1, 0.15, and 0.2 since these were the suggest values I found online to use for dropout betwen pooling layers. Each of these values were tested with each of the learning rates that were tested. \n",
    "\n",
    "Originally I tested it with Normalization layers instead but this gave similar results to the original model so the idea was scrapped. Dropout layers and Normalization were not used together since using Dropout layer with normalization removes the benefit of normalization. \n",
    "\n",
    "With these changes the model result ended up being more accurate but I struggled to get the full model to compile before my PC gave out and the python kernel crashed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = models.Sequential()\n",
    "model2.add(layers.Conv2D(32, (3,3), activation = 'relu', input_shape =(80,60,3)))\n",
    "model2.add(layers.MaxPooling2D((2,2)))\n",
    "model2.add(layers.Dropout(0.2))\n",
    "model2.add(layers.Conv2D(64, (3,3), activation = 'relu'))\n",
    "model2.add(layers.MaxPooling2D((2,2)))\n",
    "model2.add(layers.Dropout(0.2))\n",
    "model2.add(layers.Conv2D(64, (3,3), activation = 'relu'))\n",
    "model2.add(layers.MaxPooling2D((2,2)))\n",
    "model2.add(layers.Dropout(0.2))\n",
    "model2.add(layers.Conv2D(64, (3,3), activation = 'relu'))\n",
    "model2.add(layers.MaxPooling2D((2,2)))\n",
    "model2.add(layers.Dropout(0.2))\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dense(512, activation='relu'))\n",
    "model2.add(layers.Dense(13, activation='softmax'))\n",
    "model2.compile(opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My solution to this was to run the model for small number of epochs then save the model. I could look at the first printed counter value to see which epoch range I was in when it crashed. I could then reload the notebook at the last saved model and continue running more epochs. Since the model was created with an optimizer built into it originally, the same optimizer continues from where it left off.\n",
    "\n",
    "This allowed me to run the model until it converged while tracking which number the model converged at. The final upgraded model converged to around 0.9760 for accurracy and scored a 0.9622 on accurracy for the testing data which is almost 2% higher than the original model even though the model scored slightly worse on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this only when the model fails\n",
    "#set counter to whatever the value was when it last failed\n",
    "counter = 0\n",
    "# load in model2 last save\n",
    "model2 = models.load_model(\"model_upgrade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "632/632 [==============================] - 74s 117ms/step - loss: 0.0703 - accuracy: 0.9757\n",
      "Epoch 2/5\n",
      "632/632 [==============================] - 74s 116ms/step - loss: 0.0682 - accuracy: 0.9759\n",
      "Epoch 3/5\n",
      "632/632 [==============================] - 74s 117ms/step - loss: 0.0690 - accuracy: 0.9756\n",
      "Epoch 4/5\n",
      "632/632 [==============================] - 74s 117ms/step - loss: 0.0679 - accuracy: 0.9766\n",
      "Epoch 5/5\n",
      "632/632 [==============================] - 74s 117ms/step - loss: 0.0682 - accuracy: 0.9759\n",
      "total epoch run for is: 75\n",
      "63/63 [==============================] - 2s 22ms/step - loss: 0.1595 - accuracy: 0.9622\n",
      "test loss, test acc: [0.1595330387353897, 0.9622499942779541]\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(X, Y, epochs=5, batch_size = 64, verbose = 1)\n",
    "counter = counter + 5\n",
    "print(\"total epoch run for is:\", counter)\n",
    "results = model2.evaluate(X_test, Y_test, batch_size=64)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: test\\assets\n"
     ]
    }
   ],
   "source": [
    "model2.save(\"model_upgrade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 78, 58, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 39, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 39, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 37, 27, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 18, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 6, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 3, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               98816     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 13)                6669      \n",
      "=================================================================\n",
      "Total params: 198,733\n",
      "Trainable params: 198,733\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
