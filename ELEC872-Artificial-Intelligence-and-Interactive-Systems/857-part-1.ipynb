{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import cv2\n","import os\n","from keras.callbacks import EarlyStopping\n","from keras.layers import Dense, Conv2D,  MaxPool2D, Flatten, GlobalAveragePooling2D,  BatchNormalization, Layer, Add\n","from keras.models import Sequential\n","from keras.models import Model\n","import tensorflow as tf\n","import keras\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# seed the pseudorandom number generator\n","from random import seed\n","from random import random\n","# seed random number generator\n","seed(1)\n","# generate some random numbers\n","print(random(), random(), random())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#load in the data\n","train_img = []\n","train_labels = []\n","\n","test_img = []\n","test_labels = []\n","\n","path_train = ('/kaggle/input/brain-tumor-classification-mri/Training/')\n","path_test = ('/kaggle/input/brain-tumor-classification-mri/Testing/')\n","img_size= 128\n","\n","for i in os.listdir(path_train):\n","    for j in os.listdir(path_train+i):\n","        if i == \"no_tumor\":\n","            train_labels.append(0)\n","            train_img.append(cv2.cvtColor(cv2.resize(cv2.imread(path_train+i+'/'+j), (img_size,img_size)), cv2.COLOR_BGR2GRAY))\n","        else:\n","            if random() < 1:\n","                train_labels.append(1)\n","                train_img.append(cv2.cvtColor(cv2.resize(cv2.imread(path_train+i+'/'+j), (img_size,img_size)), cv2.COLOR_BGR2GRAY))\n","\n","\n","for i in os.listdir(path_test):\n","    for j in os.listdir(path_test+i):\n","        test_img.append(cv2.cvtColor(cv2.resize(cv2.imread(path_test+i+'/'+j), (img_size,img_size)), cv2.COLOR_BGR2GRAY))\n","        if i == \"no_tumor\":\n","            test_labels.append(0)\n","        else:\n","            test_labels.append(1)\n","        \n","train_img = (np.array(train_img))\n","test_img = (np.array(test_img))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#possibly add data augmentation here to try to improve performance, decided on clahe to enhance image, and median filter to average out noise.\n","#canny was added as another preprocessing step for feature extraction\n","clahe_train = []\n","clahe_test = []\n","\n","median_filter = np.ones((3,3),np.float32)/9\n","clahe = cv2.createCLAHE(clipLimit =2.0, tileGridSize=(8,8))\n","for i in range(len(train_img)):\n","    clahe_train.append(cv2.Canny(clahe.apply((cv2.filter2D(np.uint8(train_img[i]),-1,median_filter))), threshold1=100, threshold2=200))\n","\n","train_img = np.array(clahe_train)\n","\n","for i in range(len(test_img)):\n","    clahe_test.append(cv2.Canny(clahe.apply((cv2.filter2D(np.uint8(test_img[i]),-1,median_filter))), threshold1=100, threshold2=200))\n","\n","test_img = np.array(clahe_test)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#normalize images\n","train_img_normalized = train_img/255\n","test_img_normalized = test_img/255"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["input_size = train_img_normalized.size/128/128"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#train and validation split\n","from sklearn.model_selection import train_test_split\n","X_train, X_val, y_train, y_val = train_test_split(train_img_normalized, np.array(train_labels), test_size=0.33, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#loop to vary svm paremeters to find a good fit\n","from sklearn import svm\n","from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\n","\n","kernel_type = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n","degree = [2, 3, 4, 5, 6, 7, 8, 9]\n","best_recall = 0.0\n","for i in range(len(kernel_type)):\n","    for j in range(len(degree)):\n","        clf = svm.SVC(kernel = kernel_type[i], degree = degree[j])\n","        clf.fit(X_train.reshape(int(X_train.size/128/128), 128*128), np.array(y_train))\n","        y_pred_test = clf.predict(X_val.reshape(int(X_val.size/128/128), 128*128))\n","        print(i)\n","        print(j)\n","        print('Model f1 score: {0:0.4f}'. format(f1_score(np.array(y_val), y_pred_test)))\n","        print('Model accurracy score: {0:0.4f}'. format(accuracy_score(np.array(y_val), y_pred_test)))i\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#final svm\n","clf = svm.SVC(kernel = \"rbf\", degree = 4)\n","clf.fit(X_train.reshape(int(X_train.size/128/128), 128*128), np.array(y_train))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["y_pred_test = clf.predict(test_img_normalized.reshape(int(test_img_normalized.size/128/128), 128*128))\n","print(y_pred_test)\n","from sklearn.metrics import accuracy_score\n","print('Model accuracy score: {0:0.4f}'. format(accuracy_score(np.array(test_labels), y_pred_test)))\n","print('Model precision score: {0:0.4f}'. format(precision_score(np.array(test_labels), y_pred_test)))\n","print('Model recall score: {0:0.4f}'. format(recall_score(np.array(test_labels), y_pred_test)))\n","print('Model F1 score: {0:0.4f}'. format(f1_score(np.array(test_labels), y_pred_test)))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#loop to vary RF paremeters to find a good fit\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import recall_score\n","#intial number of trees, best was 100 so decreasing range number_of_trees = [100, 250, 500, 750, 1000]\n","number_of_trees = [20, 40, 60, 80, 100]\n","#initial max depth was, 12 was best so putting more values around 12 max_depth = [6, 9, 12, 15, 18]\n","max_depth = [10,11, 12, 13, 14]\n","crit = [\"gini\", \"entropy\"]\n","best_recall = 0.0\n","for i in range(len(max_depth)):\n","    for j in range(len(number_of_trees)):\n","        for k in range(len(crit)):\n","            clf = RandomForestClassifier(max_depth=max_depth[i], criterion = crit[k], n_estimators = number_of_trees[j], random_state=0)\n","            clf.fit(X_train.reshape(int(X_train.size/128/128), 128*128), np.array(y_train))\n","            y_pred_test = clf.predict(X_val.reshape(int(X_val.size/128/128), 128*128))\n","            print(i)\n","            print(j)\n","            print(k)\n","            print('Model recall score: {0:0.4f}'. format(recall_score(np.array(y_val), y_pred_test)))\n","            print('Model accurracy score: {0:0.4f}'. format(accuracy_score(np.array(y_val), y_pred_test)))\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#from the loops above got optimal RF\n","clf = RandomForestClassifier(max_depth=12, criterion = \"gini\", n_estimators = 20, random_state=0)\n","clf.fit(train_img_normalized.reshape(int(train_img_normalized.size/128/128), 128*128), np.array(train_labels))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["y_pred_test = clf.predict(test_img_normalized.reshape(int(test_img_normalized.size/128/128), 128*128))\n","print('Model accuracy score: {0:0.4f}'. format(accuracy_score(np.array(test_labels), y_pred_test)))\n","print('Model precision score: {0:0.4f}'. format(precision_score(np.array(test_labels), y_pred_test)))\n","print('Model recall score: {0:0.4f}'. format(recall_score(np.array(test_labels), y_pred_test)))\n","print('Model F1 score: {0:0.4f}'. format(f1_score(np.array(test_labels), y_pred_test)))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#loop to vary KNN paremeters to find a good fit\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","number_of_neighbors = [2, 3, 4, 5, 6]\n","algo = [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]\n","weights = [\"uniform\", \"distance\"]\n","\n","for i in range(len(number_of_neighbors)):\n","    for j in range(len(algo)):\n","        for k in range(len(weights)):\n","            clf = KNeighborsClassifier(n_neighbors=number_of_neighbors[i], algorithm = algo[j], weights = weights[k])\n","            clf.fit(X_train.reshape(int(X_train.size/128/128), 128*128), np.array(y_train))\n","            y_pred_test = clf.predict(X_val.reshape(int(X_val.size/128/128), 128*128))\n","            print(i)\n","            print(j)\n","            print(k)\n","            print('Model recall score: {0:0.4f}'. format(recall_score(np.array(y_val), y_pred_test)))\n","            print('Model accurracy score: {0:0.4f}'. format(accuracy_score(np.array(y_val), y_pred_test)))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#optimal KNN\n","clf = KNeighborsClassifier(n_neighbors=number_of_neighbors[1], algorithm = algo[2], weights = weights[1])\n","clf.fit(X_train.reshape(int(X_train.size/128/128), 128*128), np.array(y_train))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["y_pred_test = clf.predict(test_img_normalized.reshape(int(test_img_normalized.size/128/128), 128*128))\n","print('Model accuracy score: {0:0.4f}'. format(accuracy_score(np.array(test_labels), y_pred_test)))\n","print('Model precision score: {0:0.4f}'. format(precision_score(np.array(test_labels), y_pred_test)))\n","print('Model recall score: {0:0.4f}'. format(recall_score(np.array(test_labels), y_pred_test)))\n","print('Model F1 score: {0:0.4f}'. format(f1_score(np.array(test_labels), y_pred_test)))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#output confusion matrix\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","cm = confusion_matrix(np.array(test_labels), y_pred_test, labels=clf.classes_)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n","disp.plot()\n","plt.show()\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
