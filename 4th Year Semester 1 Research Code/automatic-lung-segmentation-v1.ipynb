{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport tensorflow as tf\nimport pandas as pd\nfrom tqdm import tqdm\nimport os\nfrom cv2 import imread, createCLAHE \nimport cv2\nfrom glob import glob\n%matplotlib inline\nimport matplotlib.pyplot as plt\n!pip install patchify\nimage_path = os.path.join(\"../input/chest-xray-masks-and-labels/Lung Segmentation/CXR_png/\")\nmask_path = os.path.join(\"../input/chest-xray-masks-and-labels/Lung Segmentation/masks/\")\n","metadata":{"execution":{"iopub.status.busy":"2021-12-07T19:32:50.004458Z","iopub.execute_input":"2021-12-07T19:32:50.004749Z","iopub.status.idle":"2021-12-07T19:33:03.14435Z","shell.execute_reply.started":"2021-12-07T19:32:50.004643Z","shell.execute_reply":"2021-12-07T19:33:03.143404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we have 704 masks but 800 images. Hence we are going to\n# make a 1-1 correspondance from mask to images, not the usual other way.\nimages = os.listdir(image_path)\nmask = os.listdir(mask_path)\nmask = [fName.split(\".png\")[0] for fName in mask]\nimage_file_name = [fName.split(\"_mask\")[0] for fName in mask]","metadata":{"execution":{"iopub.status.busy":"2021-12-07T19:33:03.146475Z","iopub.execute_input":"2021-12-07T19:33:03.146744Z","iopub.status.idle":"2021-12-07T19:33:03.546265Z","shell.execute_reply.started":"2021-12-07T19:33:03.146709Z","shell.execute_reply":"2021-12-07T19:33:03.545525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check = [i for i in mask if \"mask\" in i]\nprint(\"Total mask that has modified name:\",len(check))","metadata":{"execution":{"iopub.status.busy":"2021-12-07T19:33:03.547797Z","iopub.execute_input":"2021-12-07T19:33:03.54833Z","iopub.status.idle":"2021-12-07T19:33:03.553729Z","shell.execute_reply.started":"2021-12-07T19:33:03.548292Z","shell.execute_reply":"2021-12-07T19:33:03.553035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing_files = set(os.listdir(image_path)) & set(os.listdir(mask_path))\ntraining_files = check\n\ndef getData(X_shape, flag = \"test\"):\n    im_array = []\n    mask_array = []\n    kernel = np.ones((3,3),np.float32)/9\n    if flag == \"test\":\n        for i in tqdm(testing_files): \n            im = cv2.resize(cv2.imread(os.path.join(image_path,i)),(X_shape,X_shape))[:,:,0]            \n            im = cv2.filter2D(im,-1,kernel)\n            mask = cv2.resize(cv2.imread(os.path.join(mask_path,i)),(X_shape,X_shape))[:,:,0]\n            im_array.append(im)\n            mask_array.append(mask)\n        \n        return im_array,mask_array\n    \n    if flag == \"train\":\n        for i in tqdm(training_files): \n            im = cv2.resize(cv2.imread(os.path.join(image_path,i.split(\"_mask\")[0]+\".png\")),(X_shape,X_shape))[:,:,0]\n            im = cv2.filter2D(im,-1,kernel)\n            mask = cv2.resize(cv2.imread(os.path.join(mask_path,i+\".png\")),(X_shape,X_shape))[:,:,0]\n\n            im_array.append(im)\n            mask_array.append(mask)\n\n        return im_array,mask_array","metadata":{"execution":{"iopub.status.busy":"2021-12-07T19:33:03.624033Z","iopub.execute_input":"2021-12-07T19:33:03.624457Z","iopub.status.idle":"2021-12-07T19:33:03.635774Z","shell.execute_reply.started":"2021-12-07T19:33:03.624427Z","shell.execute_reply":"2021-12-07T19:33:03.634981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#perform sanity check\n\ndef plotMask(X,y):\n    sample = []\n    \n    for i in range(6):\n        left = X[i]\n        right = y[i]\n        combined = np.hstack((left,right))\n        sample.append(combined)\n        \n        \n    for i in range(0,6,3):\n\n        plt.figure(figsize=(25,10))\n        \n        plt.subplot(2,3,1+i)\n        plt.imshow(sample[i])\n        \n        plt.subplot(2,3,2+i)\n        plt.imshow(sample[i+1])\n        \n        \n        plt.subplot(2,3,3+i)\n        plt.imshow(sample[i+2])\n        \n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-07T19:33:03.555825Z","iopub.execute_input":"2021-12-07T19:33:03.55634Z","iopub.status.idle":"2021-12-07T19:33:03.565225Z","shell.execute_reply.started":"2021-12-07T19:33:03.556305Z","shell.execute_reply":"2021-12-07T19:33:03.564478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load training and testing data\ndim = 512\nprint(dim)\nX_train_1,y_train_1 = getData(dim,flag=\"train\")\nX, y = getData(dim)\n\n#X = X + X_train_1\n#y = y + y_train_1","metadata":{"execution":{"iopub.status.busy":"2021-12-07T19:33:12.131618Z","iopub.execute_input":"2021-12-07T19:33:12.131882Z","iopub.status.idle":"2021-12-07T19:35:53.222533Z","shell.execute_reply.started":"2021-12-07T19:33:12.13185Z","shell.execute_reply":"2021-12-07T19:35:53.221803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import patchify\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport random\n\n\na_list = list(range(0, 138))\nX_train = []\nX_validate = []\nX_test = []\ny_train = []\ny_validate = []\ny_test = []\n\ni = 0\nwhile i < 80:\n    temp = random.randint(0, len(a_list)-1)\n    X_train.append(X[a_list[temp]])\n    y_train.append(y[a_list[temp]])\n    del a_list[temp]\n    i = i+1\n\ni = 0\nwhile i < 20:\n    temp = random.randint(0, len(a_list)-1)\n    X_validate.append(X[a_list[temp]])\n    y_validate.append(y[a_list[temp]])\n    del a_list[temp]\n    i = i + 1\n\ni = 0\nwhile i < 38:\n    temp = random.randint(0, len(a_list)-1)\n    X_test.append(X[a_list[temp]])\n    y_test.append(y[a_list[temp]])\n    del a_list[temp]\n    i = i + 1\n\n#create pachify arrays\n\nX_patchify_train = []\nY_patchify_train = []\nX_patchify_validate = []\nY_patchify_validate = []\nX_patchify_test = []\nY_patchify_test = []\n\n#create loop to patchify each image and its mask\n    \nfor image in X_train:\n    patches = patchify.patchify(image, (32, 32), step=32)\n    X_patchify_train.append(patches)\n    \nfor image in y_train:\n    patches = patchify.patchify(image, (32, 32), step=32)\n    Y_patchify_train.append(patches)\n    \nfor image in X_validate:\n    patches = patchify.patchify(image, (32, 32), step=32)\n    X_patchify_validate.append(patches)\n    \nfor image in y_validate:\n    patches = patchify.patchify(image, (32, 32), step=32)\n    Y_patchify_validate.append(patches)\n\nfor image in X_test:\n    patches = patchify.patchify(image, (32, 32), step=32)\n    X_patchify_test.append(patches)\n    \nfor image in y_test:\n    patches = patchify.patchify(image, (32, 32), step=32)\n    Y_patchify_test.append(patches)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T19:35:53.224387Z","iopub.execute_input":"2021-12-07T19:35:53.224868Z","iopub.status.idle":"2021-12-07T19:35:53.824007Z","shell.execute_reply.started":"2021-12-07T19:35:53.22483Z","shell.execute_reply":"2021-12-07T19:35:53.823262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_patchify_train_status = []\nY_patchify_validate_status = []\nY_patchify_test_status = []\n\nX_patchify_train_updated = []\nX_patchify_validate_updated = []\nX_patchify_test_updated = []\n\ntrain_ignore = []\nvalidate_ignore = []\ntest_ignore = []\n\n\nfor patches in Y_patchify_train:\n    for i in range(patches.shape[0]):\n        for j in range(patches.shape[1]):\n            if np.mean(patches[i][j]) >= 51:\n                Y_patchify_train_status.append((1,0))\n                X_patchify_train_updated.append(patches[i][j]) \n            else:\n                Y_patchify_train_status.append((0,1))\n                X_patchify_train_updated.append(patches[i][j])\n                \n\ncounter = 0\ncounter2 = 0\nfor patches in Y_patchify_validate:\n    for i in range(patches.shape[0]):\n        for j in range(patches.shape[1]):\n            if np.mean(patches[i][j]) >= 51:\n                Y_patchify_validate_status.append((1,0))\n                X_patchify_validate_updated.append(patches[i][j])\n                \n            else:\n                Y_patchify_validate_status.append((0,1))\n                X_patchify_validate_updated.append(patches[i][j])\n                \n\nprint(counter)\nprint(counter2)\n\nfor patches in Y_patchify_test:\n    for i in range(patches.shape[0]):\n        for j in range(patches.shape[1]):\n            if np.mean(patches[i][j]) >= 51:\n                Y_patchify_test_status.append((1,0))\n                X_patchify_test_updated.append(patches[i][j])\n            else:\n                Y_patchify_test_status.append((0,1))\n                X_patchify_test_updated.append(patches[i][j])","metadata":{"execution":{"iopub.status.busy":"2021-12-07T19:35:53.825502Z","iopub.execute_input":"2021-12-07T19:35:53.82575Z","iopub.status.idle":"2021-12-07T19:35:54.388785Z","shell.execute_reply.started":"2021-12-07T19:35:53.825715Z","shell.execute_reply":"2021-12-07T19:35:54.388007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(Y_patchify_train_status))\nprint(len(X_patchify_train_updated))\nprint(len(Y_patchify_validate_status))\nprint(len(X_patchify_validate_updated))\nprint(len(Y_patchify_test_status))\nprint(len(X_patchify_test_updated))","metadata":{"execution":{"iopub.status.busy":"2021-12-07T19:35:54.390793Z","iopub.execute_input":"2021-12-07T19:35:54.391047Z","iopub.status.idle":"2021-12-07T19:35:54.398874Z","shell.execute_reply.started":"2021-12-07T19:35:54.391009Z","shell.execute_reply":"2021-12-07T19:35:54.398088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#nparrays for the patches\nprint(len(Y_patchify_train_status))\nprint(len(Y_patchify_test_status))\nY_patchify_train_status = np.array(Y_patchify_train_status).reshape(len(Y_patchify_train_status),2)\nY_patchify_validate_status = np.array(Y_patchify_validate_status).reshape(len(Y_patchify_validate_status),2)\nY_patchify_test_status = np.array(Y_patchify_test_status).reshape(len(Y_patchify_test_status),2)\n#big number from taking total entries and dividing them by image size\nX_patchify_train_updated = np.array(X_patchify_train_updated).reshape(len(X_patchify_train_updated),32,32,1)\nX_patchify_test_updated = np.array(X_patchify_test_updated).reshape(len(X_patchify_test_updated),32,32,1)\nX_patchify_validate_updated = np.array(X_patchify_validate_updated).reshape(len(X_patchify_validate_updated),32,32,1)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T19:35:54.400079Z","iopub.execute_input":"2021-12-07T19:35:54.400348Z","iopub.status.idle":"2021-12-07T19:35:54.521023Z","shell.execute_reply.started":"2021-12-07T19:35:54.400312Z","shell.execute_reply":"2021-12-07T19:35:54.520267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\n\nimport matplotlib.pyplot as plt\nimport os\nimport time\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(filters=96, kernel_size=(3,3), strides=(1,1), activation='relu', input_shape=(32,32,1)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n    tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n    tf.keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(4096, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(4096, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(2, activation='softmax')\n])\n","metadata":{"execution":{"iopub.status.busy":"2021-12-07T19:35:54.522484Z","iopub.execute_input":"2021-12-07T19:35:54.522757Z","iopub.status.idle":"2021-12-07T19:35:57.977584Z","shell.execute_reply.started":"2021-12-07T19:35:54.522721Z","shell.execute_reply":"2021-12-07T19:35:57.97688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n              loss=tf.keras.losses.BinaryCrossentropy(),\n              metrics=[tf.keras.metrics.BinaryAccuracy(),\n                       tf.keras.metrics.AUC()])\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-07T19:35:57.981447Z","iopub.execute_input":"2021-12-07T19:35:57.983351Z","iopub.status.idle":"2021-12-07T19:35:58.020978Z","shell.execute_reply.started":"2021-12-07T19:35:57.983313Z","shell.execute_reply":"2021-12-07T19:35:58.02032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_history = model.fit(x = X_patchify_train_updated,\n                         y = Y_patchify_train_status,\n                         batch_size = 128,\n                         epochs = 20,\n                         validation_data =(X_patchify_validate_updated,Y_patchify_validate_status))","metadata":{"execution":{"iopub.status.busy":"2021-12-07T19:35:58.024894Z","iopub.execute_input":"2021-12-07T19:35:58.02686Z","iopub.status.idle":"2021-12-07T19:37:21.069654Z","shell.execute_reply.started":"2021-12-07T19:35:58.026809Z","shell.execute_reply":"2021-12-07T19:37:21.068602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score, acc, *is_anything_else_being_returned = model.evaluate(X_patchify_test_updated,Y_patchify_test_status)\nprint('Test score:', score)\nprint('Test accuracy:', acc)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T19:37:21.071226Z","iopub.execute_input":"2021-12-07T19:37:21.071511Z","iopub.status.idle":"2021-12-07T19:37:23.962909Z","shell.execute_reply.started":"2021-12-07T19:37:21.071474Z","shell.execute_reply":"2021-12-07T19:37:23.962086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#save model if needed\n#model.save('./my_model')","metadata":{"execution":{"iopub.status.busy":"2021-11-16T21:19:32.955914Z","iopub.execute_input":"2021-11-16T21:19:32.956347Z","iopub.status.idle":"2021-11-16T21:19:32.959985Z","shell.execute_reply.started":"2021-11-16T21:19:32.95631Z","shell.execute_reply":"2021-11-16T21:19:32.959304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!zip -r file.zip ./my_model","metadata":{"execution":{"iopub.status.busy":"2021-11-16T21:19:32.961525Z","iopub.execute_input":"2021-11-16T21:19:32.962052Z","iopub.status.idle":"2021-11-16T21:19:32.969268Z","shell.execute_reply.started":"2021-11-16T21:19:32.962007Z","shell.execute_reply":"2021-11-16T21:19:32.968585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load model that was trained\n#model = tf.keras.models.load_model(\n#    '../input/automatic-lung-segmentation-model-part-1/my_model', custom_objects=None, compile=True, options=None\n#)","metadata":{"execution":{"iopub.status.busy":"2021-11-16T21:19:32.970369Z","iopub.execute_input":"2021-11-16T21:19:32.970717Z","iopub.status.idle":"2021-11-16T21:19:32.977097Z","shell.execute_reply.started":"2021-11-16T21:19:32.970682Z","shell.execute_reply":"2021-11-16T21:19:32.976455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"import glob\ncovid_data = []\nX_patchify_covid = []\n\nclahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(5,5))\n\n\nfor file in glob.glob(\"../input/jpg-test/COVID-5.png\"):\n    print(file)\n    img = cv2.resize(cv2.imread(file, cv2.IMREAD_GRAYSCALE), (512, 512))\n    #img = clahe.apply(img)\n    img = cv2.equalizeHist(img)\n    covid_data.append(img)\n\nfor image in covid_data:\n    patches = patchify.patchify(np.array(image), (32, 32), step=2)\n    X_patchify_covid.append(patches)\n    \nX_patchify_covid = np.float16(np.array(X_patchify_covid).reshape(58081,32,32,1))\n\nY_patchify_covid = model.predict(X_patchify_covid)\n\nresults = []\ncounter = 0\ncounter2 = 0\nfor element in Y_patchify_covid:\n    if element[0] > element[1]:\n        results.append(1)\n        counter += 1\n    else:\n        results.append(0)\n        counter2 += 1\n    \ni = 0\nj = 0\nk = 0\ncounter = 0\n\ncovid_masks = []\n\ncount1 = 0\ncount2 = 0\n\nprint(len(covid_data))\nwhile i < 1:\n    j =0\n    global temp\n    temp = np.zeros((512, 512))\n    while j < 512:\n        k=0\n        while k < 512:\n            if j > 497 and (k < 260 and k > 240):\n                temp[j][k] = 255\n                temp[j-1][k] = 255\n                temp[j][k-1] = 255\n                temp[j-1][k-1] = 255\n            elif k < 15 or j < 15 or k > 497 or j > 497:\n                temp[j][k] = 0\n                temp[j-1][k] = 0\n                temp[j][k-1] = 0\n                temp[j-1][k-1] = 0\n            elif results[counter] == 0:\n                temp[j][k] = 255\n                temp[j-1][k] = 255\n                temp[j][k-1] = 255\n                temp[j-1][k-1] = 255\n                counter += 1\n                \n            else:\n                temp[j][k] = 0\n                temp[j-1][k] = 0\n                temp[j][k-1] = 0\n                temp[j-1][k-1] = 0\n                counter += 1\n            k=k+2\n        j=j+2\n    covid_masks.append(temp)\n    i = i + 1\n    \n#test maps\nimport matplotlib.pyplot as plt \nplt.imshow(covid_masks[0]) \nplt.show() \n","metadata":{"execution":{"iopub.status.busy":"2021-10-29T18:05:39.679812Z","iopub.execute_input":"2021-10-29T18:05:39.680088Z","iopub.status.idle":"2021-10-29T18:05:40.73634Z","shell.execute_reply.started":"2021-10-29T18:05:39.680059Z","shell.execute_reply":"2021-10-29T18:05:40.735224Z"}}},{"cell_type":"code","source":"#create pachify arrays\nX_patchify_train_2 = []\nY_patchify_train_2 = []\nX_patchify_validate_2 = []\nY_patchify_validate_2 = []\n\n\nfor image in X_train:\n    patches = patchify.patchify(image, (32, 32), step=2)\n    X_patchify_train_2.append(patches)\n    \nfor image in y_train:\n    patches = patchify.patchify(image, (32, 32), step=2)\n    Y_patchify_train_2.append(patches)\n    \nfor image in X_validate:\n    patches = patchify.patchify(image, (32, 32), step=2)\n    X_patchify_validate_2.append(patches)\n    \nfor image in y_validate:\n    patches = patchify.patchify(image, (32, 32), step=2)\n    Y_patchify_validate_2.append(patches)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-16T21:19:32.97832Z","iopub.execute_input":"2021-11-16T21:19:32.978685Z","iopub.status.idle":"2021-11-16T21:19:33.002922Z","shell.execute_reply.started":"2021-11-16T21:19:32.978642Z","shell.execute_reply":"2021-11-16T21:19:33.002105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ndel score, acc, X_train, X_validate, X, y\ndel Y_patchify_train_status,Y_patchify_validate_status, Y_patchify_test_status, X_patchify_train_updated ,X_patchify_test_updated, X_patchify_validate_updated \ndel Y_patchify_test, Y_patchify_validate, Y_patchify_train\ngc.collect","metadata":{"execution":{"iopub.status.busy":"2021-11-16T21:19:33.004177Z","iopub.execute_input":"2021-11-16T21:19:33.00444Z","iopub.status.idle":"2021-11-16T21:19:33.017457Z","shell.execute_reply.started":"2021-11-16T21:19:33.004405Z","shell.execute_reply":"2021-11-16T21:19:33.01667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_patchify_train_2 = (np.array(X_patchify_train_2).reshape(4646480,32,32,1))\nY_patchify_train_2_prediction = model.predict(X_patchify_train_2)\n\ndel X_patchify_train_2\ngc.collect\n\n\nX_patchify_validate_2 = (np.array(X_patchify_validate_2).reshape(1161620,32,32,1))\nY_patchify_validate_2_prediction = model.predict(X_patchify_validate_2)\ndel X_patchify_validate_2\ngc.collect\n\ntest_result = []\ntrain_result = []\nvalidate_result = []\n\nfor element in Y_patchify_train_2_prediction:\n    if element[0] > element[1]:\n        train_result.append(1)\n    else:\n        train_result.append(0)\n\nfor element in Y_patchify_validate_2_prediction:\n    if element[0] > element[1]:\n        validate_result.append(1)\n    else:\n        validate_result.append(0)\n        \n","metadata":{"execution":{"iopub.status.busy":"2021-11-16T21:19:33.019276Z","iopub.execute_input":"2021-11-16T21:19:33.019687Z","iopub.status.idle":"2021-11-16T21:26:43.076894Z","shell.execute_reply.started":"2021-11-16T21:19:33.019648Z","shell.execute_reply":"2021-11-16T21:26:43.076104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_patchify_test_2 = []\nY_patchify_test_2 = []\n\nfor image in X_test:\n    patches = patchify.patchify(image, (32, 32), step=2)\n    X_patchify_test_2.append(patches)\n    \nfor image in y_test:\n    patches = patchify.patchify(image, (32, 32), step=2)\n    Y_patchify_test_2.append(patches)\n\nX_patchify_test_2 = (np.array(X_patchify_test_2).reshape(2207078,32,32,1))\nY_patchify_test_2_prediction = model.predict(X_patchify_test_2)\n\nfor element in Y_patchify_test_2_prediction:\n    if element[0] > element[1]:\n        test_result.append(1)\n    else:\n        test_result.append(0)","metadata":{"execution":{"iopub.status.busy":"2021-11-16T21:26:43.078139Z","iopub.execute_input":"2021-11-16T21:26:43.07842Z","iopub.status.idle":"2021-11-16T21:29:25.821245Z","shell.execute_reply.started":"2021-11-16T21:26:43.078387Z","shell.execute_reply":"2021-11-16T21:29:25.820466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del X_patchify_test_2\ngc.collect","metadata":{"execution":{"iopub.status.busy":"2021-11-16T21:29:25.82244Z","iopub.execute_input":"2021-11-16T21:29:25.824603Z","iopub.status.idle":"2021-11-16T21:29:25.836385Z","shell.execute_reply.started":"2021-11-16T21:29:25.824571Z","shell.execute_reply":"2021-11-16T21:29:25.835622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i = 0\nj = 0\nk = 0\n\ntrain_masks_2 = []\n\ncount1 = 0\ncount2 = 0\ncounter = 0\n\nwhile i < 80:\n    j = 0\n    global temp\n    temp = np.zeros((512, 512))\n    while j < 512:\n        k=0\n        while k < 512:\n            if j > 497 and (k < 260 and k > 240):\n                temp[j][k] = 255\n                temp[j-1][k] = 255\n                temp[j][k-1] = 255\n                temp[j-1][k-1] = 255\n            elif k < 15 or j < 15 or k > 497 or j > 497:\n                temp[j][k] = 0\n                temp[j-1][k] = 0\n                temp[j][k-1] = 0\n                temp[j-1][k-1] = 0\n            elif train_result[counter] == 0:\n                temp[j][k] = 255\n                temp[j-1][k] = 255\n                temp[j][k-1] = 255\n                temp[j-1][k-1] = 255\n                counter = counter + 1\n            else:\n                temp[j][k] = 0\n                temp[j-1][k] = 0\n                temp[j][k-1] = 0\n                temp[j-1][k-1] = 0\n                counter = counter + 1\n            k=k+2\n        j=j+2\n    train_masks_2.append(temp)\n    i = i + 1","metadata":{"execution":{"iopub.status.busy":"2021-11-16T21:29:25.838095Z","iopub.execute_input":"2021-11-16T21:29:25.838372Z","iopub.status.idle":"2021-11-16T21:29:40.048436Z","shell.execute_reply.started":"2021-11-16T21:29:25.838337Z","shell.execute_reply":"2021-11-16T21:29:40.047689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i = 0\nj = 0\nk = 0\n\nvalidate_masks_2 = []\n\ncount1 = 0\ncount2 = 0\ncounter = 0\n\nwhile i < 20:\n    j = 0\n    global temp\n    temp = np.zeros((512, 512))\n    while j < 512:\n        k=0\n        while k < 512:\n            if j > 497 and (k < 260 and k > 240):\n                temp[j][k] = 255\n                temp[j-1][k] = 255\n                temp[j][k-1] = 255\n                temp[j-1][k-1] = 255\n            elif k < 15 or j < 15 or k > 497 or j > 497:\n                temp[j][k] = 0\n                temp[j-1][k] = 0\n                temp[j][k-1] = 0\n                temp[j-1][k-1] = 0\n            elif validate_result[counter] == 0:\n                temp[j][k] = 255\n                temp[j-1][k] = 255\n                temp[j][k-1] = 255\n                temp[j-1][k-1] = 255\n                counter = counter + 1\n            else:\n                temp[j][k] = 0\n                temp[j-1][k] = 0\n                temp[j][k-1] = 0\n                temp[j-1][k-1] = 0\n                counter = counter + 1\n            k=k+2\n        j=j+2\n    validate_masks_2.append(temp)\n    i = i + 1","metadata":{"execution":{"iopub.status.busy":"2021-11-16T21:29:40.04972Z","iopub.execute_input":"2021-11-16T21:29:40.049955Z","iopub.status.idle":"2021-11-16T21:29:43.425753Z","shell.execute_reply.started":"2021-11-16T21:29:40.049923Z","shell.execute_reply":"2021-11-16T21:29:43.424995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i = 0\nj = 0\nk = 0\n\ntest_masks_2 = []\n\ncount1 = 0\ncount2 = 0\ncounter = 0\n\nwhile i < 38:\n    j = 0\n    global temp\n    temp = np.zeros((512, 512))\n    while j < 512:\n        k=0\n        while k < 512:\n            if j > 497 and (k < 260 and k > 240):\n                temp[j][k] = 255\n                temp[j-1][k] = 255\n                temp[j][k-1] = 255\n                temp[j-1][k-1] = 255\n            elif k < 15 or j < 15 or k > 497 or j > 497:\n                temp[j][k] = 0\n                temp[j-1][k] = 0\n                temp[j][k-1] = 0\n                temp[j-1][k-1] = 0\n            elif test_result[counter] == 0:\n                temp[j][k] = 255\n                temp[j-1][k] = 255\n                temp[j][k-1] = 255\n                temp[j-1][k-1] = 255\n                counter = counter + 1\n            else:\n                temp[j][k] = 0\n                temp[j-1][k] = 0\n                temp[j][k-1] = 0\n                temp[j-1][k-1] = 0\n                counter = counter + 1\n            k=k+2\n        j=j+2\n    test_masks_2.append(temp)\n    i = i + 1","metadata":{"execution":{"iopub.status.busy":"2021-11-16T21:29:43.426949Z","iopub.execute_input":"2021-11-16T21:29:43.427223Z","iopub.status.idle":"2021-11-16T21:29:50.074212Z","shell.execute_reply.started":"2021-11-16T21:29:43.427173Z","shell.execute_reply":"2021-11-16T21:29:50.073474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test maps\nimport matplotlib.pyplot as plt \nplt.imshow(train_masks_2[6]) \nplt.show() ","metadata":{"execution":{"iopub.status.busy":"2021-11-16T21:29:50.075352Z","iopub.execute_input":"2021-11-16T21:29:50.077312Z","iopub.status.idle":"2021-11-16T21:29:50.304795Z","shell.execute_reply.started":"2021-11-16T21:29:50.077279Z","shell.execute_reply":"2021-11-16T21:29:50.304055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage.morphology import erosion, dilation, closing\nimport cv2 as cv\nimport scipy\n#create masks for operations\n\ncross = np.zeros((19,19))\ni = 0\nwhile i < 19:\n    cross[9][i] = 1\n    cross[i][9] = 1\n    i = i + 1\n    \ndef create_circular_mask(h, w, center=None, radius=None):\n\n    if center is None: # use the middle of the image\n        center = (int(w/2), int(h/2))\n    if radius is None: # use the smallest distance between the center and image walls\n        radius = min(center[0], center[1], w-center[0], h-center[1])\n\n    Y, X = np.ogrid[:h, :w]\n    dist_from_center = np.sqrt((X - center[0])**2 + (Y-center[1])**2)\n\n    mask = dist_from_center <= radius\n    return mask\n\ncircle_dilation = create_circular_mask(15,15)\ncircle_dilation = circle_dilation.astype(int)\n\ncircle_closing = create_circular_mask(19,19)\ncircle_closing = circle_closing.astype(int)\n\ndef get_contour_areas(contours):\n\n    all_areas= []\n\n    for cnt in contours:\n        area= cv2.contourArea(cnt)\n        all_areas.append(area)\n\n    return all_areas\n\nupdated_test_masks = []\ni = 0\nwhile i < 38:\n\n    img = erosion(test_masks_2[i], cross)\n    img = dilation(img, circle_dilation)\n    ret, thresh = cv.threshold(img, 127, 255, 0)\n    thresh = thresh.astype(int)\n    contours, hierarchy = cv.findContours(thresh, cv2.RETR_FLOODFILL, cv2.CHAIN_APPROX_SIMPLE)\n\n    sorted_contours= sorted(contours, key=cv2.contourArea, reverse= True)\n    temp = np.zeros((512,512), dtype=np.uint8)\n\n    if cv2.pointPolygonTest(sorted_contours[0], (256, 500), False) == 1:\n        try:\n            cv2.fillPoly(temp, pts = [sorted_contours[2]], color=(255,255,255))\n            cv2.fillPoly(temp, pts = [sorted_contours[4]], color=(255,255,255))\n        except:\n            print(1)\n    elif cv2.pointPolygonTest(sorted_contours[2], (256, 500), False) == 1:\n        try:\n            cv2.fillPoly(temp, pts = [sorted_contours[0]], color=(255,255,255))\n            cv2.fillPoly(temp, pts = [sorted_contours[4]], color=(255,255,255))\n        except:\n            print(2)\n    else:\n        try:\n            cv2.fillPoly(temp, pts = [sorted_contours[0]], color=(255,255,255))\n            cv2.fillPoly(temp, pts = [sorted_contours[2]], color=(255,255,255))\n        except:\n            print(3)\n    temp = closing(temp, circle_closing)\n    updated_test_masks.append(temp)\n    i = i + 1\n    \n    \nupdated_train_masks = []\ni = 0\nwhile i < 80:\n\n    img = erosion(train_masks_2[i], cross)\n    img = dilation(img, circle_dilation)\n    ret, thresh = cv.threshold(img, 127, 255, 0)\n    thresh = thresh.astype(int)\n    contours, hierarchy = cv.findContours(thresh, cv2.RETR_FLOODFILL, cv2.CHAIN_APPROX_SIMPLE)\n\n    sorted_contours= sorted(contours, key=cv2.contourArea, reverse= True)\n    temp = np.zeros((512,512), dtype=np.uint8)\n\n    if cv2.pointPolygonTest(sorted_contours[0], (256, 500), False) == 1:\n        try:\n            cv2.fillPoly(temp, pts = [sorted_contours[2]], color=(255,255,255))\n            cv2.fillPoly(temp, pts = [sorted_contours[4]], color=(255,255,255))\n        except:\n            print(1)\n    elif cv2.pointPolygonTest(sorted_contours[2], (256, 500), False) == 1:\n        try:\n            cv2.fillPoly(temp, pts = [sorted_contours[0]], color=(255,255,255))\n            cv2.fillPoly(temp, pts = [sorted_contours[4]], color=(255,255,255))\n        except:\n            print(2)\n    else:\n        try:\n            cv2.fillPoly(temp, pts = [sorted_contours[0]], color=(255,255,255))\n            cv2.fillPoly(temp, pts = [sorted_contours[2]], color=(255,255,255))\n        except:\n            print(3)\n\n    \n    temp = closing(temp, circle_closing)\n    updated_train_masks.append(temp)\n    i = i + 1\n    \nupdated_validate_masks = []\ni = 0\nwhile i < 20:\n\n    img = erosion(validate_masks_2[i], cross)\n    img = dilation(img, circle_dilation)\n    ret, thresh = cv.threshold(img, 127, 255, 0)\n    thresh = thresh.astype(int)\n    contours, hierarchy = cv.findContours(thresh, cv2.RETR_FLOODFILL, cv2.CHAIN_APPROX_SIMPLE)\n\n    sorted_contours= sorted(contours, key=cv2.contourArea, reverse= True)\n    temp = np.zeros((512,512), dtype=np.uint8)\n\n    if cv2.pointPolygonTest(sorted_contours[0], (256, 500), False) == 1:\n        try:\n            cv2.fillPoly(temp, pts = [sorted_contours[2]], color=(255,255,255))\n            cv2.fillPoly(temp, pts = [sorted_contours[4]], color=(255,255,255))\n        except:\n            print(1)\n    elif cv2.pointPolygonTest(sorted_contours[2], (256, 500), False) == 1:\n        try:\n            cv2.fillPoly(temp, pts = [sorted_contours[0]], color=(255,255,255))\n            cv2.fillPoly(temp, pts = [sorted_contours[4]], color=(255,255,255))\n        except:\n            print(2)\n    else:\n        try:\n            cv2.fillPoly(temp, pts = [sorted_contours[0]], color=(255,255,255))\n            cv2.fillPoly(temp, pts = [sorted_contours[2]], color=(255,255,255))\n        except:\n            print(3)\n\n    \n    temp = closing(temp, circle_closing)\n    updated_validate_masks.append(temp)\n    i = i + 1\n\nupdate_validate_masks_final = []\nfor image in updated_validate_masks:\n    temp = (cv2.resize(image, dsize=(128, 128), interpolation=cv2.INTER_CUBIC))\n    temp = np.reshape(temp, (128, 128, 1))\n    update_validate_masks_final.append(temp)\n\nupdate_test_masks_final = []\nfor image in updated_test_masks:\n    temp = (cv2.resize(image, dsize=(128, 128), interpolation=cv2.INTER_CUBIC))\n    temp = np.reshape(temp, (128, 128, 1))\n    update_test_masks_final.append(temp)\n    \nupdate_train_masks_final = []\nfor image in updated_train_masks:\n    temp = (cv2.resize(image, dsize=(128, 128), interpolation=cv2.INTER_CUBIC))\n    temp = np.reshape(temp, (128, 128, 1))\n    update_train_masks_final.append(temp)\n\nplt.imshow(temp)\nprint(i)","metadata":{"execution":{"iopub.status.busy":"2021-11-16T21:29:50.306051Z","iopub.execute_input":"2021-11-16T21:29:50.306312Z","iopub.status.idle":"2021-11-16T21:30:34.199137Z","shell.execute_reply.started":"2021-11-16T21:29:50.306277Z","shell.execute_reply":"2021-11-16T21:30:34.198468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_small = []\ny_validate_small = []\ny_test_small = []\n\nfor image in y_train:\n    temp = (cv2.resize(image, dsize=(128, 128), interpolation=cv2.INTER_CUBIC))\n    temp = np.reshape(temp, (128, 128, 1))\n    y_train_small.append(temp)\nfor image in y_validate:\n    temp = (cv2.resize(image, dsize=(128, 128), interpolation=cv2.INTER_CUBIC))\n    temp = np.reshape(temp, (128, 128, 1))\n    y_validate_small.append(temp)\nfor image in y_test:\n    temp = (cv2.resize(image, dsize=(128, 128), interpolation=cv2.INTER_CUBIC))\n    temp = np.reshape(temp, (128, 128, 1))\n    y_test_small.append(temp)","metadata":{"execution":{"iopub.status.busy":"2021-11-16T21:30:34.200647Z","iopub.execute_input":"2021-11-16T21:30:34.201134Z","iopub.status.idle":"2021-11-16T21:30:34.249465Z","shell.execute_reply.started":"2021-11-16T21:30:34.201096Z","shell.execute_reply":"2021-11-16T21:30:34.248841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nResNet-18\nReference:\n[1] K. He et al. Deep Residual Learning for Image Recognition. CVPR, 2016\n[2] K. He, X. Zhang, S. Ren, and J. Sun. Delving deep into rectifiers:\nSurpassing human-level performance on imagenet classification. In\nICCV, 2015.\n\"\"\"\n\n\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import Dense, Conv2D,  MaxPool2D, Flatten, GlobalAveragePooling2D,  BatchNormalization, Layer, Add, Reshape\nfrom keras.models import Sequential\nfrom keras.models import Model\nimport tensorflow as tf\n\n\nclass ResnetBlock(Model):\n    \"\"\"\n    A standard resnet block.\n    \"\"\"\n\n    def __init__(self, channels: int, down_sample=False):\n        \"\"\"\n        channels: same as number of convolution kernels\n        \"\"\"\n        super().__init__()\n\n        self.__channels = channels\n        self.__down_sample = down_sample\n        self.__strides = [2, 1] if down_sample else [1, 1]\n\n        KERNEL_SIZE = (3, 3)\n        # use He initialization, instead of Xavier (a.k.a 'glorot_uniform' in Keras), as suggested in [2]\n        INIT_SCHEME = \"he_normal\"\n\n        self.conv_1 = Conv2D(self.__channels, strides=self.__strides[0],\n                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n        self.bn_1 = BatchNormalization()\n        self.conv_2 = Conv2D(self.__channels, strides=self.__strides[1],\n                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n        self.bn_2 = BatchNormalization()\n        self.merge = Add()\n\n        if self.__down_sample:\n            # perform down sampling using stride of 2, according to [1].\n            self.res_conv = Conv2D(\n                self.__channels, strides=2, kernel_size=(1, 1), kernel_initializer=INIT_SCHEME, padding=\"same\")\n            self.res_bn = BatchNormalization()\n\n    def call(self, inputs):\n        res = inputs\n\n        x = self.conv_1(inputs)\n        x = self.bn_1(x)\n        x = tf.nn.relu(x)\n        x = self.conv_2(x)\n        x = self.bn_2(x)\n\n        if self.__down_sample:\n            res = self.res_conv(res)\n            res = self.res_bn(res)\n\n        # if not perform down sample, then add a shortcut directly\n        x = self.merge([x, res])\n        out = tf.nn.relu(x)\n        return out\n\n\nclass ResNet18(Model):\n\n    def __init__(self, num_classes, **kwargs):\n        \"\"\"\n            num_classes: number of classes in specific classification task.\n        \"\"\"\n        super().__init__(**kwargs)\n        self.conv_1 = Conv2D(64, (7, 7), strides=2,\n                             padding=\"same\", kernel_initializer=\"he_normal\")\n        self.init_bn = BatchNormalization()\n        self.pool_2 = MaxPool2D(pool_size=(3, 3), strides=2, padding=\"same\")\n        self.res_1_1 = ResnetBlock(64)\n        self.res_1_2 = ResnetBlock(64)\n        self.res_2_1 = ResnetBlock(128, down_sample=True)\n        self.res_2_2 = ResnetBlock(128)\n        self.res_3_1 = ResnetBlock(256, down_sample=True)\n        self.res_3_2 = ResnetBlock(256)\n        self.res_4_1 = ResnetBlock(512, down_sample=True)\n        self.res_4_2 = ResnetBlock(512)\n        self.max_pool = MaxPool2D(pool_size=(3, 3), strides=2, padding=\"same\")\n        self.flat = Flatten()\n        self.fc = Dense(256*256, activation=\"sigmoid\")\n        \n        self.reshape = Reshape((256, 256, 1), input_shape=(65536,))\n        self.max_pool_2 = MaxPool2D(pool_size=(3, 3), strides=2, padding=\"same\")\n\n    def call(self, inputs):\n        out = self.conv_1(inputs)\n        out = self.init_bn(out)\n        out = tf.nn.relu(out)\n        out = self.pool_2(out)\n        for res_block in [self.res_1_1, self.res_1_2, self.res_2_1, self.res_2_2, self.res_3_1, self.res_3_2, self.res_4_1, self.res_4_2]:\n            out = res_block(out)\n        out = self.max_pool(out)\n        out = self.flat(out)\n        out = self.fc(out)\n        out = self.reshape(out)\n        out = self.max_pool_2(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-11-16T21:30:34.25093Z","iopub.execute_input":"2021-11-16T21:30:34.251233Z","iopub.status.idle":"2021-11-16T21:30:34.273115Z","shell.execute_reply.started":"2021-11-16T21:30:34.251182Z","shell.execute_reply":"2021-11-16T21:30:34.272501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = ResNet18(2)\nmodel.build(input_shape = (None,128,128,1))\n#use categorical_crossentropy since the label is one-hot encoded\n\nopt = tf.keras.optimizers.Adam(learning_rate=0.001)\n\nmodel.compile(optimizer = opt,loss='binary_crossentropy', metrics=[\"accuracy\"])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-16T21:30:34.27449Z","iopub.execute_input":"2021-11-16T21:30:34.274759Z","iopub.status.idle":"2021-11-16T21:30:34.71257Z","shell.execute_reply.started":"2021-11-16T21:30:34.274724Z","shell.execute_reply":"2021-11-16T21:30:34.709254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#copy y_test_small for later\nY_gt = y_test_small\nupdate_train_masks_final = np.array(update_train_masks_final).reshape(80, 128,128, 1).astype(\"float32\")/255\ny_train_small = np.array(y_train_small).reshape(80, 128,128, 1).astype(\"float32\")/255\nupdate_validate_masks_final = np.array(update_validate_masks_final).reshape(20, 128,128, 1).astype(\"float32\")/255\ny_validate_small = np.array(y_validate_small).reshape(20, 128,128, 1).astype(\"float32\")/255\nupdate_test_masks_final = np.array(update_test_masks_final).reshape(38, 128,128, 1).astype(\"float32\")/255\ny_test_small = np.array(y_test_small).reshape(38, 128,128, 1).astype(\"float32\")/255\nprint(update_train_masks_final.size)","metadata":{"execution":{"iopub.status.busy":"2021-11-16T21:30:34.713927Z","iopub.execute_input":"2021-11-16T21:30:34.714172Z","iopub.status.idle":"2021-11-16T21:30:34.737395Z","shell.execute_reply.started":"2021-11-16T21:30:34.714138Z","shell.execute_reply":"2021-11-16T21:30:34.736706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_history = model.fit(x = update_train_masks_final,\n                         y = y_train_small,\n                         batch_size = 2,\n                         epochs = 30,\n                         shuffle = True,\n                         validation_data =(update_validate_masks_final,y_validate_small))","metadata":{"execution":{"iopub.status.busy":"2021-11-16T21:30:34.73858Z","iopub.execute_input":"2021-11-16T21:30:34.738951Z","iopub.status.idle":"2021-11-16T21:31:18.126882Z","shell.execute_reply.started":"2021-11-16T21:30:34.738918Z","shell.execute_reply":"2021-11-16T21:31:18.126049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score, acc, *is_anything_else_being_returned = model.evaluate(update_test_masks_final,y_test_small)\nprint('Test score:', score)\nprint('Test accuracy:', acc)","metadata":{"execution":{"iopub.status.busy":"2021-11-16T21:31:18.128641Z","iopub.execute_input":"2021-11-16T21:31:18.129608Z","iopub.status.idle":"2021-11-16T21:31:18.821346Z","shell.execute_reply.started":"2021-11-16T21:31:18.12957Z","shell.execute_reply":"2021-11-16T21:31:18.8205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn\nfrom scipy import ndimage, misc\nGT = Y_gt\ninitial_output = []\nfor i in range(len(update_test_masks_final)):\n    initial_output.append(model.predict(update_test_masks_final[i].reshape(1,128, 128, 1)))\n    \nfor i in range(len(initial_output)):\n    initial_output[i] = initial_output[i] > 0.35\n\nfor i in range(len(initial_output)):\n    initial_output[i] = ndimage.median_filter(initial_output[i], size=5)\n\ninitial_output = np.array(initial_output).reshape(622592)\n\nGT = np.array(GT).reshape(622592) > 240\n\naccurracy = sklearn.metrics.accuracy_score(GT,initial_output)\nprint(\"This is the accurracy output:\")\nprint(accurracy)\nprecision = sklearn.metrics.precision_score(GT,initial_output)\nprint(\"This is the precision output:\")\nprint(precision)\nf1 = sklearn.metrics.f1_score(GT,initial_output)\nprint(\"This is the f1 score output:\")\nprint(f1)\ninitial_output = np.array(initial_output).reshape(38, 128, 128, 1)\nGT = (np.array(GT).reshape(38, 128, 128, 1))","metadata":{"execution":{"iopub.status.busy":"2021-11-16T21:33:27.953865Z","iopub.execute_input":"2021-11-16T21:33:27.954417Z","iopub.status.idle":"2021-11-16T21:33:30.809659Z","shell.execute_reply.started":"2021-11-16T21:33:27.954378Z","shell.execute_reply":"2021-11-16T21:33:30.808887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(Y_gt[3].reshape(128,128,1))","metadata":{"execution":{"iopub.status.busy":"2021-11-16T21:31:22.077273Z","iopub.execute_input":"2021-11-16T21:31:22.077529Z","iopub.status.idle":"2021-11-16T21:31:22.295786Z","shell.execute_reply.started":"2021-11-16T21:31:22.077494Z","shell.execute_reply":"2021-11-16T21:31:22.29504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = model.predict(update_test_masks_final[3].reshape(1, 128, 128, 1))\nplt.imshow(x.reshape(128,128,1))\nprint(np.min(x))","metadata":{"execution":{"iopub.status.busy":"2021-11-16T21:31:22.296906Z","iopub.execute_input":"2021-11-16T21:31:22.297153Z","iopub.status.idle":"2021-11-16T21:31:22.60528Z","shell.execute_reply.started":"2021-11-16T21:31:22.297118Z","shell.execute_reply":"2021-11-16T21:31:22.600003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(initial_output[3].reshape(128,128,1))\nprint(np.min(x))","metadata":{"execution":{"iopub.status.busy":"2021-11-16T21:31:22.606595Z","iopub.execute_input":"2021-11-16T21:31:22.60686Z","iopub.status.idle":"2021-11-16T21:31:22.904022Z","shell.execute_reply.started":"2021-11-16T21:31:22.606823Z","shell.execute_reply":"2021-11-16T21:31:22.903125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(y_test_small[1])\nprint(np.max(x))","metadata":{"execution":{"iopub.status.busy":"2021-11-16T21:31:22.905491Z","iopub.execute_input":"2021-11-16T21:31:22.905887Z","iopub.status.idle":"2021-11-16T21:31:23.138077Z","shell.execute_reply.started":"2021-11-16T21:31:22.90585Z","shell.execute_reply":"2021-11-16T21:31:23.137369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = model.predict(update_test_masks_final[3].reshape(1, 128, 128, 1))\nplt.imshow(x.reshape(128,128,1))\nprint(np.min(x))","metadata":{"execution":{"iopub.status.busy":"2021-11-16T21:31:23.141767Z","iopub.execute_input":"2021-11-16T21:31:23.143659Z","iopub.status.idle":"2021-11-16T21:31:23.435133Z","shell.execute_reply.started":"2021-11-16T21:31:23.143622Z","shell.execute_reply":"2021-11-16T21:31:23.434424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}